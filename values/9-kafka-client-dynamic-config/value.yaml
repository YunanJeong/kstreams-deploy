#
# 헬름차트 kstreams-1.0.0
#

# Pod늘렸을 때 Consumer Group명만 같으면 개발자가 별도 로직을 쓰지 않아도, Kafka가 자동으로 분산처리해줌
replicas: 1  
podAnnotations: {}
affinity: {}
tolerations: {}
resources: {}

# e.g.)
# nodeSelector:
#   alpaka/node-type: worker
nodeSelector: {}

# Your Streams App Image.
image:
  registry: docker.wai
  repository: "yunan/kstreams-kafka-client-dynamic-config"
  tag: 0.0.1

# 환경변수
# Streams Java앱 수정없이 helm value에서 변경할 내용들을 환경변수로 처리 (input output 토픽 등)
# 개별 helm value 항목 생성은 가급적 자제하고 환경변수를 활용하자
env:
  TZ: Asia/Seoul

  # input,output 토픽명을 동적으로 수정하고 싶을시, 환경변수로 처리하자.
  INPUT_TOPIC_REGEX: "test.topic"

# Maps to Kafka Streams `application.id`
applicationId: "streams-consumer-group-name"

kafkaConnection: 
  # Kafka `bootstrap.servers`
  bootstrapServers: "wsl:9095"
  readinessCheck:
    enabled: false
    image: bitnamilegacy/kafka:4.0.0-debian-12-r10

# Extra Kafka client properties for Streams (env: STREAMS_*).
# e.g. `producer.max.request.size` -> `STREAMS_PRODUCER_MAX_REQUEST_SIZE`
kafkaClientOverrides: # {}
  #  최초실행시(consumer-group이 없을 때) 입력 토픽을 처음(earliest)부터 읽을지, 최신(latest)부터 읽을지 결정
  #  consumer-group이 있으면 아무리 재실행해도 consumer-group의 설정을 따름
  #  보통 consumer의 default는 latest이지만, <<KStreams에서의 default는 earliest임>>
  consumer.auto.offset.reset: "earliest"
  producer.compression.type: gzip      

  # 단일 메시지 크기 10MB까지 처리하기 위한 설정
  consumer.fetch.max.bytes: "10485760"     
  consumer.max.partition.fetch.bytes: "10485760"
  producer.max.request.size: "10485760"

  # consumer.auto.offset.reset: "earliest"  # earliest(default), latest
  # auto.offset.reset: "earliest"           # used if consumer.auto.offset.reset not set
  # producer.compression.type: none         # none(default), gzip, snappy, lz4, zstd 
  # consumer.fetch.max.bytes: "1048576"     
  # consumer.max.partition.fetch.bytes: 1048576
  # producer.max.request.size: "1048576"
  


